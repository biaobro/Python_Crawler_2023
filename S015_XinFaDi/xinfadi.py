"""
# !/usr/bin/env python3
# _*_ coding:utf-8 _*_
#File               : xinfadi.py
#Project            : Crawler_2022
#CreateTime         : 2022/2/23 22:04
#Author             : biaobro
#Software           : PyCharm
#Last Modify Time   : 2022/2/23 22:04
#Version            : 1.0
#Description        : None
    # 说明
    1，页面改用XHR，所以其实不需要BeautifulSoup 了，直接用接口获取数据

    # 注意
    1，线程池，尽量不要使用全局变量
"""
import requests
import pandas as pd
import json
from concurrent.futures import ThreadPoolExecutor, as_completed
import time

url = 'http://www.xinfadi.com.cn/getPriceData.html'


def getOnePage(page_index):
    payload = {
        'limit': 20,
        'current': page_index
    }

    # post, not get
    resp = requests.post(url, data=payload)

    # print(type(resp.text))   # str
    # print(type(json.loads(resp.text)))  # dict
    # print(type(json.loads(resp.text).get('list')))  # list
    # print(json.loads(resp.text).get('list'))

    df = pd.DataFrame(json.loads(resp.text).get('list'))
    page_count = json.loads(resp.text).get('count')
    df['page_index'] = page_index
    print('total {} pages, current page {} grab done.'.format(page_count, page_index))
    return df


def getMultiPage_SimpleLoop(end):
    multiple_df = pd.DataFrame()
    for i in range(1, end):
        multiple_df = multiple_df.append(getOnePage(i))
    multiple_df.to_csv(r'data/xinfadi_simpleloop.csv', index=False)


def getMultiPage_ThreadPool(end):
    multi_df = pd.DataFrame()
    with ThreadPoolExecutor(max_workers=50) as t:
        # 写法1，注意不能通过submit直接得到返回的数据
        # obj_list = []
        # for i in range(1, end):
        #     obj = t.submit(getOnePage, i)
        #     obj_list.append(obj)

        # 写法2
        # all_futures = [t.submit(getOnePage, i) for i in range(1, end)]

        # shutdown:
        # 1, stop accepting task; 2, wait all tasks in queue done
        # 等线程全部执行完毕，再执行主线程
        # t.shutdown()

        # as_completed 只要有1个结束，就返回，他是个生成器，没有任务完成的时候会一直阻塞，除非设置timeout
        # 然后通过 future.result() 获取返回值
        # 当有某个任务完成时，会yield这个任务，就能执行for循环内的任务，然后继续阻塞，直到所有的任务结束
        # for future in as_completed(all_futures)::
        #     # print(future.result())
        #     multi_df = multi_df.append(future.result())

        # 写法3
        # map 返回的是所有线程执行完毕后返回的结果
        all_dfs = t.map(getOnePage, range(1, end))

        # map 不需要 shutdown
        for df in all_dfs:
            # append 是旧的写法，不再推荐
            # multi_df = multi_df.append(df)
            multi_df = pd.concat([multi_df, df])
        print("++++++++++++++++++++")
        # please ignore the warning generated by Pycharm
        # csv file name warning : Expect type 'None', got 'str' instead
        multi_df.to_csv(r'data/xinfadi_threadpool.csv', encoding='utf_8_sig', index=False)


if __name__ == '__main__':
    # getMultiPage_SimpleLoop(3)
    getMultiPage_ThreadPool(10)
